# ============================================================
# ðŸ¦´ Bone Tumor Outcome Prediction (MSKCC)
# Stacked Ensemble:
#   - XGBoost
#   - LightGBM
#   - CatBoost
#   - SAINT-B Tabular Transformer (bigger)
# Meta-learner: XGBoost on validation probabilities
# Includes threshold tuning for high recall on "Dead"
# ============================================================

!pip install -q xgboost lightgbm catboost torch torchvision torchaudio

from google.colab import files
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, confusion_matrix, classification_report
)

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# ------------------------------------------------------------
# 1) Upload & load dataset
# ------------------------------------------------------------
print("ðŸ“‚ Please upload your 'Bone Tumor Dataset.csv' file")
uploaded = files.upload()
filename = list(uploaded.keys())[0]

df = pd.read_csv(filename)
print("Loaded:", filename)
print("Shape:", df.shape)
print(df.head(3))

# ------------------------------------------------------------
# 2) Build target: Dead (D) vs Alive (NED + AWD)
# ------------------------------------------------------------
if "Patient ID" in df.columns:
    df = df.drop(columns=["Patient ID"])

status_col = "Status (NED, AWD, D)"
if status_col not in df.columns:
    raise KeyError(f"Column '{status_col}' not found. Available columns: {df.columns.tolist()}")

df["target"] = (df[status_col] == "D").astype(int)

X = df.drop(columns=[status_col, "target"])
y = df["target"].values

print("\nClass distribution (0=Alive, 1=Dead):")
print(df["target"].value_counts())

# ------------------------------------------------------------
# 3) Split into Train (60%) / Val (20%) / Test (20%)
# ------------------------------------------------------------
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_trainval, y_trainval, test_size=0.25, stratify=y_trainval, random_state=42
)  # 0.25 * 0.8 = 0.2

print("\nTrain size:", X_train.shape,
      "| Val size:", X_val.shape,
      "| Test size:", X_test.shape)

# ------------------------------------------------------------
# 4) Categorical & numeric columns + preprocessing
# ------------------------------------------------------------
categorical_cols = [c for c in X.columns if X[c].dtype == "object"]
numeric_cols = [c for c in X.columns if c not in categorical_cols]

print("\nCategorical columns:", categorical_cols)
print("Numeric columns:", numeric_cols)

X_train_t = X_train.copy()
X_val_t = X_val.copy()
X_test_t = X_test.copy()

# Label-encode categoricals based on TRAIN
cat_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    X_train_t[col] = le.fit_transform(X_train_t[col].astype(str))
    X_val_t[col] = le.transform(X_val_t[col].astype(str))
    X_test_t[col] = le.transform(X_test_t[col].astype(str))
    cat_encoders[col] = le

# Scale numerics based on TRAIN
scaler = StandardScaler()
if numeric_cols:
    X_train_t[numeric_cols] = scaler.fit_transform(X_train_t[numeric_cols].astype(float))
    X_val_t[numeric_cols] = scaler.transform(X_val_t[numeric_cols].astype(float))
    X_test_t[numeric_cols] = scaler.transform(X_test_t[numeric_cols].astype(float))

X_train_t = X_train_t.reset_index(drop=True)
X_val_t = X_val_t.reset_index(drop=True)
X_test_t = X_test_t.reset_index(drop=True)

# Full feature arrays for tree models (cat+num)
X_train_arr = X_train_t.values.astype(np.float32)
X_val_arr = X_val_t.values.astype(np.float32)
X_test_arr = X_test_t.values.astype(np.float32)

# Separate for SAINT
cat_train = X_train_t[categorical_cols].values.astype(np.int64) if categorical_cols else None
cat_val = X_val_t[categorical_cols].values.astype(np.int64) if categorical_cols else None
cat_test = X_test_t[categorical_cols].values.astype(np.int64) if categorical_cols else None

num_train = X_train_t[numeric_cols].values.astype(np.float32) if numeric_cols else None
num_val = X_val_t[numeric_cols].values.astype(np.float32) if numeric_cols else None
num_test = X_test_t[numeric_cols].values.astype(np.float32) if numeric_cols else None

# ------------------------------------------------------------
# 5) Tree-based base models: XGBoost, LightGBM, CatBoost
# ------------------------------------------------------------
# class imbalance ratio based on TRAIN
n_pos = (y_train == 1).sum()
n_neg = (y_train == 0).sum()
scale_pos_weight = n_neg / max(n_pos, 1)
print(f"\nscale_pos_weight for tree models: {scale_pos_weight:.3f}")

# XGBoost
xgb_model = XGBClassifier(
    n_estimators=400,
    max_depth=4,
    learning_rate=0.05,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="binary:logistic",
    eval_metric="logloss",
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    n_jobs=-1,
)
xgb_model.fit(X_train_arr, y_train)

# LightGBM
lgbm_model = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.05,
    num_leaves=31,
    subsample=0.9,
    colsample_bytree=0.9,
    class_weight={0: 1.0, 1: float(scale_pos_weight)},
    random_state=42,
    n_jobs=-1,
)
lgbm_model.fit(X_train_arr, y_train)

# CatBoost
cat_model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.05,
    depth=6,
    loss_function="Logloss",
    eval_metric="AUC",
    verbose=False,
    random_seed=42,
    class_weights=[1.0, float(scale_pos_weight)],
)
cat_model.fit(X_train_arr, y_train)

# ------------------------------------------------------------
# 6) SAINT-B: Bigger tabular transformer
# ------------------------------------------------------------
class TabularDataset(Dataset):
    def __init__(self, cat_data, num_data, y):
        self.cat_data = cat_data
        self.num_data = num_data
        self.y = y.astype(np.float32)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        cat = self.cat_data[idx] if self.cat_data is not None else None
        num = self.num_data[idx] if self.num_data is not None else None
        label = self.y[idx]
        return cat, num, label

train_ds = TabularDataset(cat_train, num_train, y_train)
val_ds = TabularDataset(cat_val, num_val, y_val)
test_ds = TabularDataset(cat_test, num_test, y_test)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)
test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)

class SAINTTabular(nn.Module):
    def __init__(self, cat_cardinalities, num_features,
                 d_model=128, n_heads=4, n_layers=4, dropout=0.2):
        super().__init__()
        self.has_cat = len(cat_cardinalities) > 0
        self.has_num = num_features > 0

        self.d_model = d_model

        if self.has_cat:
            self.cat_embeddings = nn.ModuleList(
                [nn.Embedding(card, d_model) for card in cat_cardinalities]
            )
        if self.has_num:
            self.num_linear = nn.Linear(num_features, d_model)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=n_heads,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True,
            activation="gelu",
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)

        self.norm = nn.LayerNorm(d_model)

        self.fc = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, 1)
        )

    def forward(self, cat_data, num_data):
        tokens = []

        if self.has_cat and cat_data is not None:
            cat_embs = []
            for i, emb in enumerate(self.cat_embeddings):
                cat_embs.append(emb(cat_data[:, i]))  # (B, d_model)
            cat_embs = torch.stack(cat_embs, dim=1)  # (B, n_cat, d_model)
            tokens.append(cat_embs)

        if self.has_num and num_data is not None:
            num_emb = self.num_linear(num_data)      # (B, d_model)
            num_emb = num_emb.unsqueeze(1)          # (B, 1, d_model)
            tokens.append(num_emb)

        x = torch.cat(tokens, dim=1)                # (B, seq_len, d_model)
        x = self.transformer(x)                     # (B, seq_len, d_model)
        x = x.mean(dim=1)                           # mean pooling
        x = self.norm(x)
        logits = self.fc(x).squeeze(-1)
        return logits

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("\nUsing device:", device)

cat_cardinalities = []
if categorical_cols:
    for col in categorical_cols:
        card = len(cat_encoders[col].classes_)
        cat_cardinalities.append(card)

num_features = len(numeric_cols)

saint_model = SAINTTabular(
    cat_cardinalities=cat_cardinalities,
    num_features=num_features,
    d_model=128,
    n_heads=4,
    n_layers=4,
    dropout=0.2,
).to(device)

# Loss & optimizer for SAINT
pos_weight_torch = torch.tensor(scale_pos_weight, dtype=torch.float32, device=device)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_torch)
optimizer = torch.optim.AdamW(saint_model.parameters(), lr=1e-3, weight_decay=1e-4)

class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):
    def __init__(self, optimizer, warmup_steps, max_steps, last_epoch=-1):
        self.warmup_steps = max(1, warmup_steps)
        self.max_steps = max_steps
        super().__init__(optimizer, last_epoch)

    def get_lr(self):
        step = self.last_epoch + 1

        if step <= self.warmup_steps:
            return [base_lr * step / self.warmup_steps for base_lr in self.base_lrs]

        if step >= self.max_steps:
            return [base_lr * 0.1 for base_lr in self.base_lrs]

        progress = (step - self.warmup_steps) / (self.max_steps - self.warmup_steps)
        return [
            base_lr * 0.5 * (1 + math.cos(math.pi * progress))
            for base_lr in self.base_lrs
        ]

EPOCHS = 60
total_steps = EPOCHS * len(train_loader)
warmup_steps = int(0.1 * total_steps)

scheduler = CosineWarmupScheduler(
    optimizer,
    warmup_steps=warmup_steps,
    max_steps=total_steps
)

def get_auc_safe(y_true, y_proba):
    try:
        return roc_auc_score(y_true, y_proba)
    except ValueError:
        return np.nan

def train_epoch(model, loader, optimizer, scheduler, device):
    model.train()
    total_loss = 0.0
    all_probs = []
    all_labels = []

    for cat_batch, num_batch, y_batch in loader:
        if cat_batch is not None:
            cat_batch = cat_batch.to(device)
        if num_batch is not None:
            num_batch = num_batch.to(device)
        y_batch = y_batch.to(device)

        optimizer.zero_grad()
        logits = model(cat_batch, num_batch)
        loss = criterion(logits, y_batch)
        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss.item() * y_batch.size(0)
        probs = torch.sigmoid(logits)
        all_probs.append(probs.detach().cpu().numpy())
        all_labels.append(y_batch.detach().cpu().numpy())

    avg_loss = total_loss / len(loader.dataset)
    all_probs = np.concatenate(all_probs)
    all_labels = np.concatenate(all_labels)
    return avg_loss, all_probs, all_labels

def eval_epoch(model, loader, device):
    model.eval()
    total_loss = 0.0
    all_probs = []
    all_labels = []

    with torch.no_grad():
        for cat_batch, num_batch, y_batch in loader:
            if cat_batch is not None:
                cat_batch = cat_batch.to(device)
            if num_batch is not None:
                num_batch = num_batch.to(device)
            y_batch = y_batch.to(device)

            logits = model(cat_batch, num_batch)
            loss = criterion(logits, y_batch)

            total_loss += loss.item() * y_batch.size(0)
            probs = torch.sigmoid(logits)
            all_probs.append(probs.cpu().numpy())
            all_labels.append(y_batch.cpu().numpy())

    avg_loss = total_loss / len(loader.dataset)
    all_probs = np.concatenate(all_probs)
    all_labels = np.concatenate(all_labels)
    return avg_loss, all_probs, all_labels

# Train SAINT-B with early stopping on Val AUC
best_val_auc = -np.inf
best_state = None
patience = 12
no_improve = 0

print("\nðŸš€ Training SAINT-B Transformer (bigger, with warmup + early stopping)...")
for epoch in range(1, EPOCHS + 1):
    train_loss, train_proba, train_labels = train_epoch(saint_model, train_loader, optimizer, scheduler, device)
    val_loss, val_proba, val_labels = eval_epoch(saint_model, val_loader, device)

    train_auc = get_auc_safe(train_labels, train_proba)
    val_auc = get_auc_safe(val_labels, val_proba)

    if epoch == 1 or epoch % 10 == 0:
        print(
            f"Epoch {epoch:03d}/{EPOCHS} | "
            f"Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f} | "
            f"Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}"
        )

    if val_auc > best_val_auc:
        best_val_auc = val_auc
        best_state = saint_model.state_dict()
        no_improve = 0
    else:
        no_improve += 1
        if no_improve >= patience:
            print(f"â¹ Early stopping at epoch {epoch} (no improvement in Val AUC for {patience} epochs).")
            break

print(f"\nBest SAINT-B Val AUC: {best_val_auc:.4f}")
if best_state is not None:
    saint_model.load_state_dict(best_state)

# Helper: get probabilities from SAINT
def get_saint_probs(loader, device):
    saint_model.eval()
    all_probs = []
    with torch.no_grad():
        for cat_batch, num_batch, y_batch in loader:
            if cat_batch is not None:
                cat_batch = cat_batch.to(device)
            if num_batch is not None:
                num_batch = num_batch.to(device)
            logits = saint_model(cat_batch, num_batch)
            probs = torch.sigmoid(logits)
            all_probs.append(probs.cpu().numpy())
    return np.concatenate(all_probs)

# ------------------------------------------------------------
# 7) Base model probabilities on VAL and TEST
# ------------------------------------------------------------
# Tree models
val_proba_xgb = xgb_model.predict_proba(X_val_arr)[:, 1]
test_proba_xgb = xgb_model.predict_proba(X_test_arr)[:, 1]

val_proba_lgbm = lgbm_model.predict_proba(X_val_arr)[:, 1]
test_proba_lgbm = lgbm_model.predict_proba(X_test_arr)[:, 1]

val_proba_cat = cat_model.predict_proba(X_val_arr)[:, 1]
test_proba_cat = cat_model.predict_proba(X_test_arr)[:, 1]

# SAINT-B
val_proba_saint = get_saint_probs(val_loader, device)
test_proba_saint = get_saint_probs(test_loader, device)

# ------------------------------------------------------------
# 8) Meta-learner: XGBoost on validation probabilities
# ------------------------------------------------------------
X_meta_val = np.vstack([
    val_proba_xgb,
    val_proba_lgbm,
    val_proba_cat,
    val_proba_saint,
]).T  # shape (N_val, 4)

X_meta_test = np.vstack([
    test_proba_xgb,
    test_proba_lgbm,
    test_proba_cat,
    test_proba_saint,
]).T  # shape (N_test, 4)

meta_model = XGBClassifier(
    n_estimators=300,
    max_depth=3,
    learning_rate=0.05,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="binary:logistic",
    eval_metric="logloss",
    random_state=42,
)

meta_model.fit(X_meta_val, y_val)

meta_proba_val = meta_model.predict_proba(X_meta_val)[:, 1]
meta_proba_test = meta_model.predict_proba(X_meta_test)[:, 1]

# ------------------------------------------------------------
# 9) Helper to evaluate a model
# ------------------------------------------------------------
def evaluate_probs(y_true, proba, name="Model", thr=0.5, verbose=True):
    y_pred = (proba >= thr).astype(int)
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    auc = roc_auc_score(y_true, proba)

    if verbose:
        print("\n==============================")
        print(f" {name} (thr={thr:.2f})")
        print("==============================")
        print(f"Accuracy     : {acc:.4f}")
        print(f"Precision    : {prec:.4f}")
        print(f"Recall       : {rec:.4f}")
        print(f"F1-score     : {f1:.4f}")
        print(f"AUC          : {auc:.4f}")
        print("\nClassification report:")
        print(classification_report(y_true, y_pred, target_names=["Alive", "Dead"]))

    return acc, prec, rec, f1, auc

# ------------------------------------------------------------
# 10) Evaluate base models & meta on TEST (thr=0.5)
# ------------------------------------------------------------
print("\n########## BASE MODELS ON TEST (thr=0.5) ##########")
evaluate_probs(y_test, test_proba_xgb, "XGBoost (base)")
evaluate_probs(y_test, test_proba_lgbm, "LightGBM (base)")
evaluate_probs(y_test, test_proba_cat, "CatBoost (base)")
evaluate_probs(y_test, test_proba_saint, "SAINT-B (base)")

print("\n########## META-ENSEMBLE ON TEST (thr=0.5) ##########")
evaluate_probs(y_test, meta_proba_test, "STACKED ENSEMBLE (XGB meta)")

# ------------------------------------------------------------
# 11) Threshold scanning for meta on Validation
# ------------------------------------------------------------
def scan_thresholds(y_true, y_proba, model_name="Model", min_recall=None):
    thresholds = np.linspace(0.05, 0.95, 19)
    rows = []

    for thr in thresholds:
        y_pred = (y_proba >= thr).astype(int)
        acc = accuracy_score(y_true, y_pred)
        prec = precision_score(y_true, y_pred, zero_division=0)
        rec = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        rows.append({
            "threshold": thr,
            "accuracy": acc,
            "precision": prec,
            "recall": rec,
            "f1": f1,
        })

    df_thr = pd.DataFrame(rows)

    print(f"\n==============================")
    print(f" Threshold scan for {model_name}")
    print("==============================")
    if min_recall is not None:
        df_filtered = df_thr[df_thr["recall"] >= min_recall].sort_values("f1", ascending=False)
        if df_filtered.empty:
            print(f"No threshold found with recall >= {min_recall}")
        else:
            best_row = df_filtered.iloc[0]
            print(f"Best threshold with recall >= {min_recall}:")
            print(best_row)
    else:
        df_sorted = df_thr.sort_values("f1", ascending=False)
        best_row = df_sorted.iloc[0]
        print("Best threshold by F1:")
        print(best_row)

    return df_thr

# you can change min_recall to e.g. 0.8
df_thr_meta_val = scan_thresholds(y_val, meta_proba_val,
                                  model_name="STACKED ENSEMBLE (Validation)",
                                  min_recall=0.7)

# choose best threshold (recall>=0.7 if possible, otherwise best F1)
df_thr_highrec = df_thr_meta_val[df_thr_meta_val["recall"] >= 0.7]
if not df_thr_highrec.empty:
    best_thr_row = df_thr_highrec.sort_values("f1", ascending=False).iloc[0]
else:
    best_thr_row = df_thr_meta_val.sort_values("f1", ascending=False).iloc[0]

best_thr = float(best_thr_row["threshold"])
print(f"\nðŸ”¥ Selected best threshold from VALIDATION for META: {best_thr:.3f}")
print(best_thr_row)

# ------------------------------------------------------------
# 12) Final META performance on TEST with tuned threshold
# ------------------------------------------------------------
acc_t, prec_t, rec_t, f1_t, auc_t = evaluate_probs(
    y_test, meta_proba_test,
    name=f"STACKED ENSEMBLE (TEST, tuned thr={best_thr:.3f})",
    thr=best_thr,
    verbose=True
)

# Confusion matrix for tuned meta
y_test_pred_tuned = (meta_proba_test >= best_thr).astype(int)
cm = confusion_matrix(y_test, y_test_pred_tuned)
tn, fp, fn, tp = cm.ravel()
spec = tn / (tn + fp) if (tn + fp) > 0 else np.nan
print(f"\nSpecificity (Test, tuned threshold): {spec:.4f}")

plt.figure(figsize=(4, 4))
sns.heatmap(
    cm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["Pred Alive", "Pred Dead"],
    yticklabels=["True Alive", "True Dead"]
)
plt.title(f"Confusion Matrix - STACKED ENSEMBLE (Test, thr={best_thr:.2f})")
plt.tight_layout()
plt.show()

# ROC curve for meta on TEST
fpr, tpr, _ = roc_curve(y_test, meta_proba_test)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"STACKED ENSEMBLE Test (AUC = {auc_t:.4f})")
plt.plot([0, 1], [0, 1], "--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - STACKED ENSEMBLE (Test)")
plt.legend()
plt.grid(True, linestyle="--", alpha=0.7)
plt.tight_layout()
plt.show()
